{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f22b4ed",
   "metadata": {},
   "source": [
    "# Monitoring ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764abb2e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c631b6c7",
   "metadata": {},
   "source": [
    "### Testing endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21c951c",
   "metadata": {},
   "source": [
    "Loading the data from a list of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "aab8dfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"VAR2\": \"M\",\n",
      "        \"IDADE\": 43.893,\n",
      "        \"VAR5\": \"PR\",\n",
      "        \"VAR6\": -25.4955709,\n",
      "        \"VAR7\": -49.2454987,\n",
      "        \"VAR8\": \"D\",\n",
      "        \"VAR9\": \"E\",\n",
      "        \"VAR10\": \"MEDIA\",\n",
      "        \"VAR11\": 1.0,\n",
      "        \"VAR12\": 0.182,\n",
      "        \"VAR14\": 0.597,\n",
      "        \"VAR15\": 0.618,\n",
      "        \"VAR16\": 0.25,\n",
      "        \"VAR18\": 1.076712,\n",
      "        \"VAR19\": 5.057534,\n",
      "        \"VAR22\": 0.125,\n",
      "        \"VAR24\": 0.069,\n",
      "        \"VAR25\": 0.0969999999999999,\n",
      "        \"VAR32\": \"SALDO INEXISTENTE\",\n",
      "        \"VAR39\": 0.661039,\n",
      "        \"VAR40\": 0.573539,\n",
      "        \"VAR41\": 0.4793699999999999,\n",
      "        \"VAR42\": 0.4440489999999999,\n",
      "        \"VAR47\": 0.006,\n",
      "        \"VAR49\": \"S\",\n",
      "        \"VAR50\": \"N\",\n",
      "        \"VAR51\": \"N\",\n",
      "        \"VAR52\": \"N\",\n",
      "        \"VAR53\": \"N\",\n",
      "        \"VAR54\": \"N\",\n",
      "        \"VAR55\": \"N\",\n",
      "        \"VAR56\": \"S\",\n",
      "        \"VAR57\": \"S\",\n",
      "        \"VAR58\": \"N\",\n",
      "        \"VAR59\": \"N\",\n",
      "        \"VAR60\": \"N\",\n",
      "        \"VAR61\": \"N\",\n",
      "        \"VAR62\": \"N\",\n",
      "        \"VAR63\": \"N\",\n",
      "        \"VAR64\": \"N\",\n",
      "        \"VAR65\": \"N\",\n",
      "        \"VAR66\": \"ALTISSIMA\",\n",
      "        \"VAR67\": \"ALTA\",\n",
      "        \"VAR68\": \"ALTISSIMA\",\n",
      "        \"VAR69\": \"ALTISSIMA\",\n",
      "        \"VAR70\": \"ALTISSIMA\",\n",
      "        \"VAR71\": \"ALTA\",\n",
      "        \"VAR72\": \"ALTISSIMA\",\n",
      "        \"VAR73\": \"ALTISSIMA\",\n",
      "        \"VAR74\": \"ALTISSIMA\",\n",
      "        \"VAR75\": \"ALTISSIMA\",\n",
      "        \"VAR76\": \"ALTA\",\n",
      "        \"VAR77\": \"ALTISSIMA\",\n",
      "        \"VAR78\": \"ALTISSIMA\",\n",
      "        \"VAR79\": \"ALTISSIMA\",\n",
      "        \"VAR80\": \"ALTA\",\n",
      "        \"VAR81\": \"ALTA\",\n",
      "        \"VAR82\": \"ALTISSIMA\",\n",
      "        \"VAR83\": \"ALTISSIMA\",\n",
      "        \"VAR84\": \"ALTA\",\n",
      "        \"VAR85\": \"ALTA\",\n",
      "        \"VAR86\": \"ALTA\",\n",
      "        \"VAR87\": \"ALTISSIMA\",\n",
      "        \"VAR88\": \"ALTA\",\n",
      "        \"VAR89\": \"ALTISSIMA\",\n",
      "        \"VAR90\": \"BAIXISSIMA\",\n",
      "        \"VAR91\": \"ALTA\",\n",
      "        \"VAR92\": \"ALTISSIMA\",\n",
      "        \"VAR93\": \"ALTISSIMA\",\n",
      "        \"VAR94\": \"ALTISSIMA\",\n",
      "        \"VAR95\": \"ALTA\",\n",
      "        \"VAR96\": \"ALTISSIMA\",\n",
      "        \"VAR97\": \"ALTA\",\n",
      "        \"VAR98\": \"ALTISSIMA\",\n",
      "        \"VAR99\": \"ALTISSIMA\",\n",
      "        \"VAR100\": \"BAIXISSIMA\",\n",
      "        \"VAR101\": \"ALTA\",\n",
      "        \"VAR102\": \"MEDIO\",\n",
      "        \"VAR103\": \"MEDIO\",\n",
      "        \"VAR104\": \"PROXIMO\",\n",
      "        \"VAR105\": \"LONGE\",\n",
      "        \"VAR106\": \"MEDIO\",\n",
      "        \"VAR107\": \"MEDIO\",\n",
      "        \"VAR108\": \"MEDIO\",\n",
      "        \"VAR109\": \"MEDIO\",\n",
      "        \"VAR110\": \"PROXIMO\",\n",
      "        \"VAR111\": \"MEDIO\",\n",
      "        \"VAR112\": \"MEDIO\",\n",
      "        \"VAR113\": \"PROXIMO\",\n",
      "        \"VAR114\": \"PROXIMO\",\n",
      "        \"VAR115\": \"MEDIO\",\n",
      "        \"VAR116\": \"LONGE\",\n",
      "        \"VAR117\": \"MEDIO\",\n",
      "        \"VAR118\": \"MEDIO\",\n",
      "        \"VAR119\": \"LONGE\",\n",
      "        \"VAR120\": \"MUITO LONGE\",\n",
      "        \"VAR121\": \"MEDIO\",\n",
      "        \"VAR122\": \"MEDIO\",\n",
      "        \"VAR123\": \"MEDIO\",\n",
      "        \"VAR124\": \"MEDIO\",\n",
      "        \"VAR125\": \"PROXIMO\",\n",
      "        \"VAR126\": \"MEDIO\",\n",
      "        \"VAR127\": \"PROXIMO\",\n",
      "        \"VAR128\": \"LONGE\",\n",
      "        \"VAR129\": \"MEDIO\",\n",
      "        \"VAR130\": \"MEDIO\",\n",
      "        \"VAR131\": \"MEDIO\",\n",
      "        \"VAR132\": \"PROXIMO\",\n",
      "        \"VAR133\": \"MEDIO\",\n",
      "        \"VAR134\": \"PROXIMO\",\n",
      "        \"VAR135\": \"MEDIO\",\n",
      "        \"VAR136\": \"MEDIO\",\n",
      "        \"VAR137\": \"MEDIO\",\n",
      "        \"VAR138\": \"MEDIO\",\n",
      "        \"VAR139\": \"MEDIO\",\n",
      "        \"VAR140\": \"MUITO PROXIMO\",\n",
      "        \"VAR141\": 3970.113648,\n",
      "        \"VAR142\": \"C\",\n",
      "        \"REF_DATE\": \"2017-03-25 00:00:00+00:00\",\n",
      "        \"TARGET\": 1\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "f = open(\"../monitoring/batch_records.json\")\n",
    "request = f.read()\n",
    "request_sample = request.split('}')\n",
    "print(request_sample[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65519c7",
   "metadata": {},
   "source": [
    "Using the requests library to send the post requests to the endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "21c89d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22958502",
   "metadata": {},
   "source": [
    "The first endpoint receives a list of records and returns two things:\n",
    "1. The volumetry (quantity of records) for each month\n",
    "2. The value of the area under the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6fe5bbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volumetry --> \n",
      "\n",
      "\"2017-07\":74\n",
      "\"2017-08\":72\n",
      "\"2017-05\":67\n",
      "\"2017-06\":63\n",
      "\"2017-03\":62\n",
      "\"2017-01\":58\n",
      "\"2017-02\":55\n",
      "\"2017-04\":49\n",
      "\n",
      "AUC ROC --> \n",
      "\n",
      "0.5751748251748252\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(url=\"http://0.0.0.0:8001/v1/performance\", data = request).text\n",
    "\n",
    "\n",
    "volumetry = response.split(\"+\")[0][2:-3].split(\",\")\n",
    "volumetry[0] =  \"Volumetry --> \\n\\n\" + volumetry[0]\n",
    "for i in range(len(volumetry)):\n",
    "    print(volumetry[i])\n",
    "\n",
    "print(\"\\nAUC ROC --> \\n\\n\"+response.split(\"+\")[1][:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebca52f7",
   "metadata": {},
   "source": [
    "The second endpoint uses the Kolmogorov-Smirnov distance to measure how far away the score distribution of a desired database is comparing to the Test Database (/datasets/credit_01/test.gz)\n",
    "The path of the desired database is passed in the Post request."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d617f3",
   "metadata": {},
   "source": [
    "Testing endpoint with train.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "44fb5564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KstestResult -->\n",
      "\n",
      "statistic=0.002759858953621075\n",
      "pvalue=0.9605978662359891\n",
      "statistic_location=0.7445096329184175\n",
      "statistic_sign=1\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/srctwd/challenge-data-scientist-ntech/datasets/credit_01/train.gz\"\n",
    "response = requests.post(url=\"http://0.0.0.0:8001/v1/aderencia\", data = path).text\n",
    "response = response.split(\",\")\n",
    "print(response[0][1:13]+\" -->\\n\")\n",
    "print(response[0][14:])\n",
    "print(response[1][1:])\n",
    "print(response[2][1:])\n",
    "print(response[3][1:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b9e0fb",
   "metadata": {},
   "source": [
    "Testing endpoint with oot.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ca778561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KstestResult -->\n",
      "\n",
      "statistic=0.020915414151451373\n",
      "pvalue=4.01624188958718e-12\n",
      "statistic_location=0.7928217560872773\n",
      "statistic_sign=1\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/srctwd/challenge-data-scientist-ntech/datasets/credit_01/oot.gz\"\n",
    "response = requests.post(url=\"http://0.0.0.0:8001/v1/aderencia\", data = path).text\n",
    "response = response.split(\",\")\n",
    "print(response[0][1:13]+\" -->\\n\")\n",
    "print(response[0][14:])\n",
    "print(response[1][1:])\n",
    "print(response[2][1:])\n",
    "print(response[3][1:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b100a3",
   "metadata": {},
   "source": [
    "From the two databases tested, we see that the score distribution of train.gz is the closest to test.gz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e24cfbe",
   "metadata": {},
   "source": [
    "### Training new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "eb7824bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f9d8e85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../datasets/credit_01/train.gz\"\n",
    "test_path = \"../datasets/credit_01/test.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f22e6b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srctwd/neurotech/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3460: DtypeWarning: Columns (45) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(train_path, compression=\"gzip\")\n",
    "df_test = pd.read_csv(test_path, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ce1ddef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    REF_DATE  TARGET VAR2   IDADE VAR4 VAR5       VAR6  \\\n",
      "0  2017-06-16 00:00:00+00:00       1    F  76.126  NaN   SP -23.568523   \n",
      "1  2017-02-07 00:00:00+00:00       1  NaN     NaN  NaN   SP -23.189738   \n",
      "2  2017-03-11 00:00:00+00:00       1  NaN     NaN  NaN   PE  -7.563015   \n",
      "3  2017-04-28 00:00:00+00:00       1    F  65.786  NaN   AM  -3.119028   \n",
      "4  2017-02-15 00:00:00+00:00       1    M  24.918  NaN   AC -10.014903   \n",
      "\n",
      "        VAR7 VAR8 VAR9  ...       VAR141  VAR142  VAR143  VAR144  VAR145  \\\n",
      "0 -46.804297    C    E  ...  4094.377623       C     NaN     NaN     NaN   \n",
      "1 -46.815943  NaN    E  ...  1347.882336       E     NaN     NaN     NaN   \n",
      "2 -35.013143  NaN    E  ...  1428.485398       E     NaN     NaN     NaN   \n",
      "3 -60.021731  NaN    E  ...  1478.879522       E     NaN     NaN     NaN   \n",
      "4 -67.798491    E    E  ...  1560.669227       E     NaN     NaN     NaN   \n",
      "\n",
      "   VAR146  VAR147                                             VAR148  VAR149  \\\n",
      "0     NaN     102  EMAIL INEXISTENTE#@#NOME INEXISTENTE#@#CEP INE...   2.6.1   \n",
      "1     NaN     102  EMAIL INEXISTENTE#@#NOME INEXISTENTE#@#CEP INE...   2.6.1   \n",
      "2     NaN     102               NOME INEXISTENTE#@#EMAIL INEXISTENTE   2.6.1   \n",
      "3     NaN     102                                  EMAIL INEXISTENTE   2.6.1   \n",
      "4     NaN     102  EMAIL INEXISTENTE#@#NOME INEXISTENTE#@#CEP INE...   2.6.1   \n",
      "\n",
      "       ID  \n",
      "0  123791  \n",
      "1  246754  \n",
      "2  169817  \n",
      "3   26525  \n",
      "4  143859  \n",
      "\n",
      "[5 rows x 151 columns]\n"
     ]
    }
   ],
   "source": [
    "df_train.fillna(value=np.nan,inplace=True)\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "092e3401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101128 entries, 0 to 101127\n",
      "Columns: 151 entries, REF_DATE to ID\n",
      "dtypes: float64(34), int64(3), object(114)\n",
      "memory usage: 116.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "3d12793e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in each column:\n",
      "REF_DATE - #unique: 242        #nan:0\n",
      "TARGET - #unique: 2        #nan:0\n",
      "VAR2 - #unique: 3        #nan:12356\n",
      "IDADE - #unique: 21359        #nan:11594\n",
      "VAR4 - #unique: 1        #nan:100944\n",
      "VAR5 - #unique: 27        #nan:2835\n",
      "VAR6 - #unique: 45233        #nan:2835\n",
      "VAR7 - #unique: 45207        #nan:2835\n",
      "VAR8 - #unique: 5        #nan:44526\n",
      "VAR9 - #unique: 5        #nan:2798\n",
      "VAR10 - #unique: 5        #nan:2770\n",
      "VAR11 - #unique: 9        #nan:38719\n",
      "VAR12 - #unique: 221        #nan:46220\n",
      "VAR13 - #unique: 916        #nan:88133\n",
      "VAR14 - #unique: 789        #nan:21411\n",
      "VAR15 - #unique: 891        #nan:52173\n",
      "VAR16 - #unique: 192        #nan:63551\n",
      "VAR17 - #unique: 2358        #nan:88133\n",
      "VAR18 - #unique: 792        #nan:21411\n",
      "VAR19 - #unique: 1886        #nan:52173\n",
      "VAR20 - #unique: 85        #nan:91606\n",
      "VAR21 - #unique: 5        #nan:88081\n",
      "VAR22 - #unique: 9        #nan:52106\n",
      "VAR23 - #unique: 91        #nan:88133\n",
      "VAR24 - #unique: 59        #nan:19685\n",
      "VAR25 - #unique: 32        #nan:52173\n",
      "VAR26 - #unique: 59        #nan:100307\n",
      "VAR27 - #unique: 7        #nan:100281\n",
      "VAR28 - #unique: 21        #nan:90386\n",
      "VAR29 - #unique: 49        #nan:80376\n",
      "VAR30 - #unique: 17        #nan:90386\n",
      "VAR31 - #unique: 7        #nan:97881\n",
      "VAR32 - #unique: 7        #nan:65931\n",
      "VAR33 - #unique: 1        #nan:93800\n",
      "VAR34 - #unique: 34        #nan:93800\n",
      "VAR35 - #unique: 1        #nan:79486\n",
      "VAR36 - #unique: 1        #nan:80339\n",
      "VAR37 - #unique: 412        #nan:80339\n",
      "VAR38 - #unique: 1        #nan:100467\n",
      "VAR39 - #unique: 62099        #nan:65\n",
      "VAR40 - #unique: 28276        #nan:2782\n",
      "VAR41 - #unique: 39282        #nan:2508\n",
      "VAR42 - #unique: 27394        #nan:11588\n",
      "VAR43 - #unique: 1        #nan:100778\n",
      "VAR44 - #unique: 98        #nan:100778\n",
      "VAR45 - #unique: 1        #nan:100867\n",
      "VAR46 - #unique: 239        #nan:100867\n",
      "VAR47 - #unique: 1000        #nan:0\n",
      "VAR48 - #unique: 2        #nan:94081\n",
      "VAR49 - #unique: 2        #nan:11592\n",
      "VAR50 - #unique: 2        #nan:11592\n",
      "VAR51 - #unique: 2        #nan:11592\n",
      "VAR52 - #unique: 2        #nan:11592\n",
      "VAR53 - #unique: 2        #nan:11592\n",
      "VAR54 - #unique: 2        #nan:11592\n",
      "VAR55 - #unique: 2        #nan:11592\n",
      "VAR56 - #unique: 2        #nan:11592\n",
      "VAR57 - #unique: 2        #nan:11592\n",
      "VAR58 - #unique: 2        #nan:11592\n",
      "VAR59 - #unique: 2        #nan:11592\n",
      "VAR60 - #unique: 2        #nan:11592\n",
      "VAR61 - #unique: 2        #nan:11592\n",
      "VAR62 - #unique: 2        #nan:11592\n",
      "VAR63 - #unique: 2        #nan:11592\n",
      "VAR64 - #unique: 2        #nan:11592\n",
      "VAR65 - #unique: 2        #nan:11592\n",
      "VAR66 - #unique: 4        #nan:2508\n",
      "VAR67 - #unique: 3        #nan:2508\n",
      "VAR68 - #unique: 4        #nan:2508\n",
      "VAR69 - #unique: 4        #nan:2508\n",
      "VAR70 - #unique: 4        #nan:2508\n",
      "VAR71 - #unique: 5        #nan:2508\n",
      "VAR72 - #unique: 4        #nan:2508\n",
      "VAR73 - #unique: 4        #nan:2508\n",
      "VAR74 - #unique: 4        #nan:2508\n",
      "VAR75 - #unique: 4        #nan:2508\n",
      "VAR76 - #unique: 4        #nan:2508\n",
      "VAR77 - #unique: 4        #nan:2508\n",
      "VAR78 - #unique: 4        #nan:2508\n",
      "VAR79 - #unique: 4        #nan:2508\n",
      "VAR80 - #unique: 4        #nan:2508\n",
      "VAR81 - #unique: 5        #nan:2508\n",
      "VAR82 - #unique: 3        #nan:2508\n",
      "VAR83 - #unique: 4        #nan:2508\n",
      "VAR84 - #unique: 4        #nan:2508\n",
      "VAR85 - #unique: 4        #nan:2508\n",
      "VAR86 - #unique: 4        #nan:2508\n",
      "VAR87 - #unique: 5        #nan:2508\n",
      "VAR88 - #unique: 5        #nan:2508\n",
      "VAR89 - #unique: 4        #nan:2508\n",
      "VAR90 - #unique: 2        #nan:2508\n",
      "VAR91 - #unique: 5        #nan:2508\n",
      "VAR92 - #unique: 4        #nan:2508\n",
      "VAR93 - #unique: 3        #nan:2508\n",
      "VAR94 - #unique: 4        #nan:2508\n",
      "VAR95 - #unique: 3        #nan:2508\n",
      "VAR96 - #unique: 5        #nan:2508\n",
      "VAR97 - #unique: 4        #nan:2508\n",
      "VAR98 - #unique: 4        #nan:2508\n",
      "VAR99 - #unique: 5        #nan:2508\n",
      "VAR100 - #unique: 2        #nan:2508\n",
      "VAR101 - #unique: 4        #nan:2508\n",
      "VAR102 - #unique: 5        #nan:2508\n",
      "VAR103 - #unique: 5        #nan:2508\n",
      "VAR104 - #unique: 5        #nan:2508\n",
      "VAR105 - #unique: 5        #nan:2508\n",
      "VAR106 - #unique: 5        #nan:2508\n",
      "VAR107 - #unique: 5        #nan:2508\n",
      "VAR108 - #unique: 5        #nan:2508\n",
      "VAR109 - #unique: 5        #nan:2508\n",
      "VAR110 - #unique: 5        #nan:2508\n",
      "VAR111 - #unique: 5        #nan:2508\n",
      "VAR112 - #unique: 5        #nan:2508\n",
      "VAR113 - #unique: 5        #nan:2508\n",
      "VAR114 - #unique: 5        #nan:2508\n",
      "VAR115 - #unique: 5        #nan:2508\n",
      "VAR116 - #unique: 5        #nan:2508\n",
      "VAR117 - #unique: 5        #nan:2508\n",
      "VAR118 - #unique: 5        #nan:2508\n",
      "VAR119 - #unique: 5        #nan:2508\n",
      "VAR120 - #unique: 2        #nan:2508\n",
      "VAR121 - #unique: 4        #nan:2508\n",
      "VAR122 - #unique: 5        #nan:2508\n",
      "VAR123 - #unique: 5        #nan:2508\n",
      "VAR124 - #unique: 5        #nan:2508\n",
      "VAR125 - #unique: 5        #nan:2508\n",
      "VAR126 - #unique: 5        #nan:2508\n",
      "VAR127 - #unique: 5        #nan:2508\n",
      "VAR128 - #unique: 5        #nan:2508\n",
      "VAR129 - #unique: 5        #nan:2508\n",
      "VAR130 - #unique: 5        #nan:2508\n",
      "VAR131 - #unique: 5        #nan:2508\n",
      "VAR132 - #unique: 5        #nan:2508\n",
      "VAR133 - #unique: 5        #nan:2508\n",
      "VAR134 - #unique: 5        #nan:2508\n",
      "VAR135 - #unique: 5        #nan:2508\n",
      "VAR136 - #unique: 5        #nan:2508\n",
      "VAR137 - #unique: 5        #nan:2508\n",
      "VAR138 - #unique: 5        #nan:2508\n",
      "VAR139 - #unique: 5        #nan:2508\n",
      "VAR140 - #unique: 5        #nan:2508\n",
      "VAR141 - #unique: 1489        #nan:0\n",
      "VAR142 - #unique: 5        #nan:123\n",
      "VAR143 - #unique: 2        #nan:99823\n",
      "VAR144 - #unique: 2        #nan:99823\n",
      "VAR145 - #unique: 384        #nan:100584\n",
      "VAR146 - #unique: 76        #nan:100989\n",
      "VAR147 - #unique: 2        #nan:0\n",
      "VAR148 - #unique: 7        #nan:0\n",
      "VAR149 - #unique: 1        #nan:0\n",
      "ID - #unique: 101128        #nan:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique values in each column:\") \n",
    "for column in df_train.columns:\n",
    "    print(column + \" - #unique: \" + str(df_train[column].nunique()) + \"        #nan:\" + str(df_train[column].isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38dae3e",
   "metadata": {},
   "source": [
    "Features that most likely do not add any value to the classification task:\n",
    "\n",
    "**REF_DATE** - date the registry was taken. Does not speak much about the individual entries\n",
    "\n",
    "**ID** - unique for each entry\n",
    "\n",
    "Missing for more than 80k entries: \n",
    "**VAR4, VAR13, VAR17, VAR20, VAR21, VAR23, VAR26, VAR27, VAR28, VAR29, VAR30, VAR31, VAR33\n",
    "VAR34, VAR36, VAR37, VAR38, VAR43, VAR44, VAR45, VAR46, VAR48, VAR143, VAR144, VAR145, VAR146**\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "73cdded2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VAR4', 'VAR13', 'VAR17', 'VAR20', 'VAR21', 'VAR23', 'VAR26', 'VAR27', 'VAR28', 'VAR29', 'VAR30', 'VAR31', 'VAR33', 'VAR34', 'VAR36', 'VAR37', 'VAR38', 'VAR43', 'VAR44', 'VAR45', 'VAR46', 'VAR48', 'VAR143', 'VAR144', 'VAR145', 'VAR146']\n"
     ]
    }
   ],
   "source": [
    "to_drop = []\n",
    "for column in df_train.columns:\n",
    "    if df_train[column].isna().sum() > 80000:\n",
    "        to_drop.append(column)\n",
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e8494ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=to_drop)\n",
    "df_train = df_train.drop(columns=[\"REF_DATE\", \"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "afe5a27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101128 entries, 0 to 101127\n",
      "Columns: 123 entries, TARGET to VAR149\n",
      "dtypes: float64(19), int64(2), object(102)\n",
      "memory usage: 94.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0c62ee",
   "metadata": {},
   "source": [
    "Checking if Dataset is balanced:\n",
    "\n",
    "We have 4x more examples of the positive class than of the negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d069084b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    80130\n",
       "0    20998\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"TARGET\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2a003f",
   "metadata": {},
   "source": [
    "Preprocessing categorical and numerical columns\n",
    "\n",
    "Source: https://inria.github.io/scikit-learn-mooc/python_scripts/03_categorical_pipeline_column_transformer.html (Scikit learn documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "551a3ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(['TARGET'], axis=1)\n",
    "\n",
    "y = df_train['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ab827484",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns_selector = selector(dtype_exclude=object)\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "\n",
    "numerical_columns = numerical_columns_selector(X)\n",
    "categorical_columns = categorical_columns_selector(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "1c845d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "numerical_preprocessor = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c79a1cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numerical_columns:\n",
    "    X[column].fillna(0, inplace=True)\n",
    "for column in categorical_columns:\n",
    "    X[column].fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2b8b32f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101128 entries, 0 to 101127\n",
      "Columns: 122 entries, VAR2 to VAR149\n",
      "dtypes: float64(19), int64(1), object(102)\n",
      "memory usage: 94.1+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "fdd9ee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "    ('standard_scaler', numerical_preprocessor, numerical_columns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2378709e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('one-hot-encoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['VAR2', 'VAR5', 'VAR8',\n",
       "                                                   'VAR9', 'VAR10', 'VAR32',\n",
       "                                                   'VAR35', 'VAR49', 'VAR50',\n",
       "                                                   'VAR51', 'VAR52', 'VAR53',\n",
       "                                                   'VAR54', 'VAR55', 'VAR56',\n",
       "                                                   'VAR57', 'VAR58', 'VAR59',\n",
       "                                                   'VAR60', 'VAR61', 'VAR62',\n",
       "                                                   'VAR63', 'VAR64', 'VAR65',\n",
       "                                                   'VAR66', 'VAR67', 'VAR68',\n",
       "                                                   'VAR69', 'VAR70', 'VAR71', ...]),\n",
       "                                                 ('standard_scaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['IDADE', 'VAR6', 'VAR7',\n",
       "                                                   'VAR11', 'VAR12', 'VAR14',\n",
       "                                                   'VAR15', 'VAR16', 'VAR18',\n",
       "                                                   'VAR19', 'VAR22', 'VAR24',\n",
       "                                                   'VAR25', 'VAR39', 'VAR40',\n",
       "                                                   'VAR41', 'VAR42', 'VAR47',\n",
       "                                                   'VAR141', 'VAR147'])])),\n",
       "                ('decisiontreeclassifier',\n",
       "                 DecisionTreeClassifier(max_depth=3, random_state=0))])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_pipeline(preprocessor, DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=0))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f8d009",
   "metadata": {},
   "source": [
    "Splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "302f7993",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c3105f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70789, 122), (30339, 122))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "9152297d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "541ca981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 70789 entries, 19537 to 15795\n",
      "Columns: 122 entries, VAR2 to VAR149\n",
      "dtypes: float64(19), int64(1), object(102)\n",
      "memory usage: 66.4+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "14743c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "df3c2fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC = roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "a74f4968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6220028045603245\n"
     ]
    }
   ],
   "source": [
    "print(AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "7a2dc554",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model_path = '../monitoring/model.pkl'\n",
    "new_model_path = '../monitoring/new_model.pkl'\n",
    "pickle.dump(model, open(new_model_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "63ac3756",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model = pickle.load(open(old_model_path, 'rb'))\n",
    "new_model = pickle.load(open(new_model_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "42975efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['VAR4', 'VAR13', 'VAR17', 'VAR20', 'VAR21', 'VAR23', 'VAR26', 'VAR27', 'VAR28', 'VAR29', 'VAR30', \n",
    "            'VAR31', 'VAR33', 'VAR34', 'VAR36', 'VAR37', 'VAR38', 'VAR43', 'VAR44', 'VAR45', 'VAR46', 'VAR48', \n",
    "            'VAR143', 'VAR144', 'VAR145', 'VAR146', 'REF_DATE', 'ID']\n",
    "def new_process_dataset(df, to_drop):\n",
    "    df.fillna(value=np.nan,inplace=True)\n",
    "    df = df.drop(columns=to_drop)\n",
    "    \n",
    "    numerical_columns_selector = selector(dtype_exclude=object)\n",
    "    categorical_columns_selector = selector(dtype_include=object)\n",
    "\n",
    "    numerical_columns = numerical_columns_selector(df)\n",
    "    categorical_columns = categorical_columns_selector(df)\n",
    "    \n",
    "    for column in numerical_columns:\n",
    "        df[column].fillna(0, inplace=True)\n",
    "    for column in categorical_columns:\n",
    "        df[column].fillna(\"\", inplace=True)\n",
    "    \n",
    "    X = df.drop(['TARGET'], axis=1)\n",
    "    y = df['TARGET']\n",
    "    return X, y\n",
    "\n",
    "def old_process_dataset(df):\n",
    "    df.fillna(value=np.nan,inplace=True)\n",
    "    df.drop([\"REF_DATE\"], axis=1)\n",
    "    \n",
    "    X = df.drop(['TARGET'], axis=1)\n",
    "    y = df['TARGET']\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2eb97e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_old_testdf, y_old_testdf = old_process_dataset(df_test)\n",
    "X_new_testdf, y_new_testdf = new_process_dataset(df_test, to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "607f7d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_old_testdf = old_model.predict_proba(X_old_testdf)[:,1]\n",
    "pred_new_testdf = new_model.predict_proba(X_new_testdf)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "db0b4c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_AUC = roc_auc_score(y_old_testdf, pred_old_testdf)\n",
    "new_AUC = roc_auc_score(y_new_testdf, pred_new_testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "67f84a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6075332746684731\n",
      "0.6192777660729909\n"
     ]
    }
   ],
   "source": [
    "print(old_AUC)\n",
    "print(new_AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83964c4a",
   "metadata": {},
   "source": [
    "With some minimal feature engineering, the Decision Tree Classifier was able to perform slightly better than the pre-trained model. \n",
    "To improve the performance further, we could use other models such as Random Forest or XGBoost. \n",
    "XGBoost model is mentioned in many sources as a really good model to use with tabular data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca0d21e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
